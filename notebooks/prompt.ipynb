{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab843caf-394e-4491-a6e1-4679053d6128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sjadhav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, T5Tokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b851d0a-9fd4-4a37-8a93-2e933554f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.20.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sjadhav\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sjadhav\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c58dfb8-9e7a-400f-a9a4-1eb52b9bcae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ai4i2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27328c7-742c-4bbc-95b2-025f7babed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Machine failure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87418d4-fd52-4e8c-9886-8a29d3ad061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e50bdf8-9a58-4b04-8b0f-c0214db1bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b4f4d79-a618-4d6b-b6b9-0d37ffbbe5ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Load Chronos (Prompt-based mode)\n",
    "model_name = \"amazon/chronos-t5-small\"\n",
    "\n",
    "# Use the slow tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", use_fast=False)\n",
    "\n",
    "# Load the T5 model using the correct class\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226c0bfd-eb2a-41e5-be70-5e67b76b30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(features):\n",
    "    \"\"\"\n",
    "    Convert structured tabular row into a text prompt for LLM.\n",
    "    Re-engineered to be a multiple-choice-style task for better zero-shot performance.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"Based on the following machine operational data, is a machine failure likely to occur?\\n\"\n",
    "        f\"Data points: UDI={features['UDI']}, Product ID={features['Product ID']}, Type={features['Type']},\\n\"\n",
    "        f\"Air Temp={features['Air temperature [K]']}, Process Temp={features['Process temperature [K]']},\\n\"\n",
    "        f\"Rotational Speed={features['Rotational speed [rpm]']}, Torque={features['Torque [Nm]']},\\n\"\n",
    "        f\"Tool Wear={features['Tool wear [min]']}, TWF={features['TWF']}, HDF={features['HDF']},\\n\"\n",
    "        f\"PWF={features['PWF']}, OSF={features['OSF']}, RNF={features['RNF']}.\\n\"\n",
    "        f\"Answer with either 'Failure is likely' or 'Failure is not likely'.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def predict_prompt_improved(row):\n",
    "    \"\"\"\n",
    "    Generate a prediction with improved parsing.\n",
    "    \"\"\"\n",
    "    prompt = create_prompt(row)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    \n",
    "    # Generate a more concise output\n",
    "    outputs = model.generate(**inputs, max_length=15, num_beams=5, early_stopping=True)\n",
    "    pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True).lower()\n",
    "    \n",
    "    # Improved parsing logic\n",
    "    if \"failure is likely\" in pred_text or \"likely\" in pred_text:\n",
    "        return 1\n",
    "    elif \"failure is not likely\" in pred_text or \"not likely\" in pred_text:\n",
    "        return 0\n",
    "    else:\n",
    "        # Fallback to simple parsing if the desired phrase isn't found\n",
    "        if \"1\" in pred_text:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "877c862f-f571-4445-b062-b9d27d70ae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Few-shot In-Context Learning Performance (Zero-shot):\n",
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "def create_few_shot_prompt(features, examples):\n",
    "    \"\"\"\n",
    "    Create a few-shot prompt with in-context examples.\n",
    "    \"\"\"\n",
    "    prompt_with_examples = \"\"\n",
    "    for ex_features, ex_label in examples:\n",
    "        prompt_with_examples += (\n",
    "            f\"Machine data: UDI={ex_features['UDI']}, Product ID={ex_features['Product ID']}, \"\n",
    "            f\"Type={ex_features['Type']}, Air Temp={ex_features['Air temperature [K]']}, \"\n",
    "            f\"Process Temp={ex_features['Process temperature [K]']}, Rotational Speed={ex_features['Rotational speed [rpm]']}, \"\n",
    "            f\"Torque={ex_features['Torque [Nm]']}, Tool Wear={ex_features['Tool wear [min]']}, \"\n",
    "            f\"TWF={ex_features['TWF']}, HDF={ex_features['HDF']}, PWF={ex_features['PWF']}, \"\n",
    "            f\"OSF={ex_features['OSF']}, RNF={ex_features['RNF']}.\\n\"\n",
    "            f\"Prediction: {'Failure' if ex_label == 1 else 'No Failure'}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # Add the new instance to the prompt\n",
    "    prompt_with_examples += (\n",
    "        f\"Machine data: UDI={features['UDI']}, Product ID={features['Product ID']}, \"\n",
    "        f\"Type={features['Type']}, Air Temp={features['Air temperature [K]']}, \"\n",
    "        f\"Process Temp={features['Process temperature [K]']}, Rotational Speed={features['Rotational speed [rpm]']}, \"\n",
    "        f\"Torque={features['Torque [Nm]']}, Tool Wear={features['Tool wear [min]']}, \"\n",
    "        f\"TWF={features['TWF']}, HDF={features['HDF']}, PWF={features['PWF']}, \"\n",
    "        f\"OSF={features['OSF']}, RNF={features['RNF']}.\\n\"\n",
    "        f\"Prediction:\"\n",
    "    )\n",
    "    return prompt_with_examples\n",
    "\n",
    "# In your main script:\n",
    "# Select a few examples from your training data (e.g., 5 examples)\n",
    "# Ensure you have a mix of positive and negative cases for balance\n",
    "example_indices = [23, 55, 120, 200, 310]\n",
    "few_shot_examples = [(X_train.iloc[i], y_train.iloc[i]) for i in example_indices]\n",
    "\n",
    "# Now, use this in your prediction loop\n",
    "def predict_few_shot(row, examples):\n",
    "    prompt = create_few_shot_prompt(row, examples)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_length=20)\n",
    "    pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True).lower()\n",
    "    \n",
    "    if \"failure\" in pred_text:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Test the new function\n",
    "y_pred_few_shot = [predict_few_shot(X_test.iloc[i], few_shot_examples) for i in range(50)]\n",
    "y_true_few_shot = y_test.iloc[:50].tolist()\n",
    "\n",
    "print(\"\\nüìä Few-shot In-Context Learning Performance (Zero-shot):\")\n",
    "print(\"Accuracy:\", np.mean(np.array(y_true_few_shot) == np.array(y_pred_few_shot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493ba42-0acd-49b7-b9a8-05031257853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Few-Shot Prompt Builder\n",
    "def create_few_shot_prompt(features, examples):\n",
    "    prompt_with_examples = \"\"\n",
    "    for ex_features, ex_label in examples:\n",
    "        prompt_with_examples += (\n",
    "            f\"Machine data: UDI={ex_features['UDI']}, Product ID={ex_features['Product ID']}, \"\n",
    "            f\"Type={ex_features['Type']}, Air Temp={ex_features['Air temperature [K]']}, \"\n",
    "            f\"Process Temp={ex_features['Process temperature [K]']}, Rotational Speed={ex_features['Rotational speed [rpm]']}, \"\n",
    "            f\"Torque={ex_features['Torque [Nm]']}, Tool Wear={ex_features['Tool wear [min]']}, \"\n",
    "            f\"TWF={ex_features['TWF']}, HDF={ex_features['HDF']}, PWF={ex_features['PWF']}, \"\n",
    "            f\"OSF={ex_features['OSF']}, RNF={ex_features['RNF']}.\\n\"\n",
    "            f\"Prediction: {'Failure' if ex_label == 1 else 'No Failure'}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    prompt_with_examples += (\n",
    "        f\"Machine data: UDI={features['UDI']}, Product ID={features['Product ID']}, \"\n",
    "        f\"Type={features['Type']}, Air Temp={features['Air temperature [K]']}, \"\n",
    "        f\"Process Temp={features['Process temperature [K]']}, Rotational Speed={features['Rotational speed [rpm]']}, \"\n",
    "        f\"Torque={features['Torque [Nm]']}, Tool Wear={features['Tool wear [min]']}, \"\n",
    "        f\"TWF={features['TWF']}, HDF={features['HDF']}, PWF={features['PWF']}, \"\n",
    "        f\"OSF={features['OSF']}, RNF={features['RNF']}.\\n\"\n",
    "        f\"Prediction:\"\n",
    "    )\n",
    "    return prompt_with_examples\n",
    "\n",
    "def predict_few_shot(row, examples):\n",
    "    prompt = create_few_shot_prompt(row, examples)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_length=20)\n",
    "    pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True).lower()\n",
    "\n",
    "    if \"failure\" in pred_text:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Automated Example Selection\n",
    "# -------------------------------\n",
    "def get_balanced_examples(X_train, y_train, n=10):\n",
    "    \"\"\"Randomly sample balanced few-shot examples.\"\"\"\n",
    "    pos_idx = y_train[y_train == 1].index.tolist()\n",
    "    neg_idx = y_train[y_train == 0].index.tolist()\n",
    "\n",
    "    pos_samples = random.sample(pos_idx, min(n//2, len(pos_idx)))\n",
    "    neg_samples = random.sample(neg_idx, min(n//2, len(neg_idx)))\n",
    "\n",
    "    indices = pos_samples + neg_samples\n",
    "    examples = [(X_train.loc[i], y_train.loc[i]) for i in indices]\n",
    "    return examples\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Run Few-Shot Inference\n",
    "# -------------------------------\n",
    "few_shot_examples = get_balanced_examples(X_train, y_train, n=20)  # try with 10, 20\n",
    "\n",
    "y_pred_few_shot = []\n",
    "for i in range(len(X_test)):\n",
    "    pred = predict_few_shot(X_test.iloc[i], few_shot_examples)\n",
    "    y_pred_few_shot.append(pred)\n",
    "\n",
    "y_true = y_test.tolist()\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Evaluation\n",
    "# -------------------------------\n",
    "acc = accuracy_score(y_true, y_pred_few_shot)\n",
    "prec = precision_score(y_true, y_pred_few_shot)\n",
    "rec = recall_score(y_true, y_pred_few_shot)\n",
    "f1 = f1_score(y_true, y_pred_few_shot)\n",
    "cm = confusion_matrix(y_true, y_pred_few_shot)\n",
    "\n",
    "print(\"\\nüìä Few-Shot In-Context Learning Performance (Chronos-T5):\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred_few_shot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433bd6c1-974d-4930-aaf8-91d9183ed260",
   "metadata": {},
   "source": [
    "Expert prompting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6be9b-7a9b-473b-8071-c3b5aff8b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_expert_prompt(features):\n",
    "    \"\"\"\n",
    "    Expert-level prompt for zero-shot machine failure prediction.\n",
    "    This prompt uses a structured, chain-of-thought approach with clear roles\n",
    "    and output formatting to guide the model to a highly accurate prediction.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are an AI assistant specialized in predictive maintenance analysis. \"\n",
    "        \"Your task is to analyze machine operational data and determine if a failure is imminent. \"\n",
    "        \"You must follow a strict three-step process to arrive at your final prediction.\\n\\n\"\n",
    "        \n",
    "        \"# Step 1: Data Analysis\\n\"\n",
    "        \"Analyze the following data points for anomalies or trends that may indicate a failure:\\n\"\n",
    "        f\"- Air Temp: {features['Air temperature [K]']} K\\n\"\n",
    "        f\"- Process Temp: {features['Process temperature [K]']} K\\n\"\n",
    "        f\"- Rotational Speed: {features['Rotational speed [rpm]']} RPM\\n\"\n",
    "        f\"- Torque: {features['Torque [Nm]']} Nm\\n\"\n",
    "        f\"- Tool Wear: {features['Tool wear [min]']} min\\n\"\n",
    "        \"Pay special attention to high values in Torque, Tool Wear, and low values in Rotational Speed. \"\n",
    "        \"Also note any active failure modes (TWF, HDF, PWF, OSF, RNF) as they are direct indicators.\\n\\n\"\n",
    "        \n",
    "        \"# Step 2: Reasoning\\n\"\n",
    "        \"Based on your analysis, explain your reasoning in a concise paragraph. \"\n",
    "        \"State whether the data points suggest a normal operation or show signs of stress. \"\n",
    "        \"Reference specific values that support your conclusion.\\n\\n\"\n",
    "        \n",
    "        \"# Step 3: Final Prediction\\n\"\n",
    "        \"State your final prediction clearly. The prediction must be a single digit, either '1' for an imminent failure or '0' for no imminent failure. \"\n",
    "        \"Do not include any other text or characters in this final line. \"\n",
    "        \"Final Prediction:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def predict_expert(row):\n",
    "    prompt = create_expert_prompt(row)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    \n",
    "    # Generate a longer response to allow for multi-step reasoning\n",
    "    outputs = model.generate(**inputs, max_length=200, num_beams=5, early_stopping=True)\n",
    "    pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Robust parsing: Find the last line and extract the digit\n",
    "    lines = pred_text.strip().split('\\n')\n",
    "    for line in reversed(lines):\n",
    "        if 'Final Prediction:' in line:\n",
    "            final_pred = line.split(':')[-1].strip()\n",
    "            if '1' in final_pred:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    return 0 # Default return if parsing fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4eb8b-8972-497c-b924-a8cae6d1fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 4. Baseline Evaluation (Prompt-based)\n",
    "y_pred_prompt = [predict_prompt(X_test.iloc[i]) for i in range(50)]  # small batch for demo\n",
    "y_true_prompt = y_test.iloc[:50].tolist()\n",
    "\n",
    "print(\"\\nüìä Prompt-based Performance (Zero-shot):\")\n",
    "print(\"Accuracy:\", np.mean(np.array(y_true_prompt) == np.array(y_pred_prompt)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true_prompt, y_pred_prompt))\"\"\"\n",
    "\n",
    "# 4. Baseline Evaluation (Prompt-based)\n",
    "y_pred_prompt = [predict_prompt_improved(X_test.iloc[i]) for i in range(50)]\n",
    "y_true_prompt = y_test.iloc[:50].tolist()\n",
    "\n",
    "print(\"\\nüìä Prompt-based Performance (Zero-shot):\")\n",
    "print(\"Accuracy:\", np.mean(np.array(y_true_prompt) == np.array(y_pred_prompt)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true_prompt, y_pred_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a881e07-0523-42a3-8606-a80137d9c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Expert-level Prompting and Prediction\n",
    "# -------------------------------\n",
    "def create_expert_prompt(features):\n",
    "    \"\"\"\n",
    "    Expert-level prompt for zero-shot machine failure prediction.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are an AI assistant specialized in predictive maintenance analysis. \"\n",
    "        \"Your task is to analyze machine operational data and determine if a failure is imminent. \"\n",
    "        \"You must follow a strict three-step process to arrive at your final prediction.\\n\\n\"\n",
    "        \n",
    "        \"# Step 1: Data Analysis\\n\"\n",
    "        \"Analyze the following data points for anomalies or trends that may indicate a failure:\\n\"\n",
    "        f\"- Air Temp: {features['Air temperature [K]']} K\\n\"\n",
    "        f\"- Process Temp: {features['Process temperature [K]']} K\\n\"\n",
    "        f\"- Rotational Speed: {features['Rotational speed [rpm]']} RPM\\n\"\n",
    "        f\"- Torque: {features['Torque [Nm]']} Nm\\n\"\n",
    "        f\"- Tool Wear: {features['Tool wear [min]']} min\\n\"\n",
    "        f\"- UDI: {features['UDI']}\\n\"\n",
    "        f\"- Product ID: {features['Product ID']}\\n\"\n",
    "        f\"- Type: {features['Type']}\\n\"\n",
    "        f\"- TWF: {features['TWF']}\\n\"\n",
    "        f\"- HDF: {features['HDF']}\\n\"\n",
    "        f\"- PWF: {features['PWF']}\\n\"\n",
    "        f\"- OSF: {features['OSF']}\\n\"\n",
    "        f\"- RNF: {features['RNF']}\\n\"\n",
    "        \"Pay special attention to high values in Torque, Tool Wear, and low values in Rotational Speed. \"\n",
    "        \"Also note any active failure modes (TWF, HDF, PWF, OSF, RNF) as they are direct indicators.\\n\\n\"\n",
    "        \n",
    "        \"# Step 2: Reasoning\\n\"\n",
    "        \"Based on your analysis, explain your reasoning in a concise paragraph. \"\n",
    "        \"State whether the data points suggest a normal operation or show signs of stress. \"\n",
    "        \"Reference specific values that support your conclusion.\\n\\n\"\n",
    "        \n",
    "        \"# Step 3: Final Prediction\\n\"\n",
    "        \"State your final prediction clearly. The prediction must be a single digit, either '1' for an imminent failure or '0' for no imminent failure. \"\n",
    "        \"Do not include any other text or characters in this final line. \"\n",
    "        \"Final Prediction:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def predict_expert(row):\n",
    "    prompt = create_expert_prompt(row)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_length=200, num_beams=5, early_stopping=True)\n",
    "    pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    lines = pred_text.strip().split('\\n')\n",
    "    for line in reversed(lines):\n",
    "        if 'Final Prediction:' in line:\n",
    "            final_pred = line.split(':')[-1].strip()\n",
    "            if '1' in final_pred:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    return 0\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Evaluation\n",
    "# -------------------------------\n",
    "sample_size = 50\n",
    "y_pred_expert = [predict_expert(X_test.iloc[i]) for i in range(sample_size)]\n",
    "y_true_expert = y_test.iloc[:sample_size].tolist()\n",
    "\n",
    "print(\"\\nüìä Expert Prompt Performance (Zero-shot):\")\n",
    "accuracy = accuracy_score(y_true_expert, y_pred_expert)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# ‚úÖ Add Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true_expert, y_pred_expert))\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Live User Input & Prediction\n",
    "# -------------------------------\n",
    "print(\"\\n--- Live Machine Failure Prediction ---\")\n",
    "print(\"Please enter the machine's current operational data:\")\n",
    "\n",
    "try:\n",
    "    user_features = {}\n",
    "    user_features['UDI'] = int(input(\"UDI: \"))\n",
    "    user_features['Product ID'] = input(\"Product ID: \")\n",
    "    user_features['Type'] = input(\"Type (e.g., L, M, H): \")\n",
    "    user_features['Air temperature [K]'] = float(input(\"Air temperature [K]: \"))\n",
    "    user_features['Process temperature [K]'] = float(input(\"Process temperature [K]: \"))\n",
    "    user_features['Rotational speed [rpm]'] = int(input(\"Rotational speed [rpm]: \"))\n",
    "    user_features['Torque [Nm]'] = float(input(\"Torque [Nm]: \"))\n",
    "    user_features['Tool wear [min]'] = float(input(\"Tool wear [min]: \"))\n",
    "    user_features['TWF'] = int(input(\"TWF (Tool Wear Failure, 0 or 1): \"))\n",
    "    user_features['HDF'] = int(input(\"HDF (Heat Dissipation Failure, 0 or 1): \"))\n",
    "    user_features['PWF'] = int(input(\"PWF (Power Failure, 0 or 1): \"))\n",
    "    user_features['OSF'] = int(input(\"OSF (Overstrain Failure, 0 or 1): \"))\n",
    "    user_features['RNF'] = int(input(\"RNF (Random Failure, 0 or 1): \"))\n",
    "    \n",
    "    # Convert user input to a pandas Series to match the model's expectation\n",
    "    user_row = pd.Series(user_features)\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = predict_expert(user_row)\n",
    "    \n",
    "    print(\"\\n--- Prediction Result ---\")\n",
    "    if prediction == 1:\n",
    "        print(\"üî¥ Prediction: The model predicts an **imminent machine failure**.\")\n",
    "    else:\n",
    "        print(\"üü¢ Prediction: The model predicts **no imminent failure**.\")\n",
    "\n",
    "except ValueError:\n",
    "    print(\"‚ùå Invalid input! Please ensure you enter the correct data type (numbers for numeric fields, etc.).\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d779b82d-34f9-413e-8012-d5c8f6083a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timesfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d94617-27c8-49b8-8ebc-0d9175c6eaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from timesfm import TimesFM\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Load TimesFM model\n",
    "timesfm_model = TimesFM()\n",
    "timesfm_model.fit(X_train, y_train)\n",
    "y_pred_timesfm = timesfm_model.predict(X_test)\n",
    "\n",
    "# Load prompt-based model\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def predict_prompt(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = outputs.logits.argmax(dim=-1).item()\n",
    "    return prediction\n",
    "\n",
    "y_pred_prompt = [predict_prompt(X_test.iloc[i]) for i in range(50)]\n",
    "y_true_prompt = y_test.iloc[:50].tolist()\n",
    "\n",
    "# Evaluate TimesFM model\n",
    "print(\"üìä TimesFM Model Performance:\")\n",
    "print(\"Accuracy:\", np.mean(y_test == y_pred_timesfm))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_timesfm))\n",
    "\n",
    "# Evaluate prompt-based model\n",
    "print(\"\\nüìä Prompt-based Model Performance:\")\n",
    "print(\"Accuracy:\", np.mean(np.array(y_true_prompt) == np.array(y_pred_prompt)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true_prompt, y_pred_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e0451-8635-47c2-9509-09cb8ff00da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# TimesFM-based model block\n",
    "# -------------------------------\n",
    "import torch\n",
    "from transformers import TimesFmModelForPrediction\n",
    "\n",
    "# Load TimesFM pretrained model\n",
    "timesfm_model = TimesFmModelForPrediction.from_pretrained(\n",
    "    \"google/timesfm-2.0-500m-pytorch\",\n",
    "    torch_dtype=torch.float32,  # or bfloat16 if your GPU supports\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "timesfm_model.to(device)\n",
    "\n",
    "def predict_with_timesfm(history_series, freq, threshold):\n",
    "    \"\"\"\n",
    "    history_series: a 1D numpy / list / tensor of past values relevant to failure signal\n",
    "    freq: frequency index if needed\n",
    "    threshold: a numeric threshold beyond which we say failure is likely\n",
    "    Returns: 1 if failure is predicted, else 0\n",
    "    \"\"\"\n",
    "    # Prepare input: convert to tensor\n",
    "    past = torch.tensor(history_series, dtype=torch.float32).to(timesfm_model.device)\n",
    "    freq_tensor = torch.tensor([freq], dtype=torch.long).to(timesfm_model.device)\n",
    "    # If needed batch dimension\n",
    "    past = past.unsqueeze(0)  # shape (batch=1, sequence_length)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = timesfm_model(past_values=past, freq=freq_tensor, return_dict=True)\n",
    "        # Get forecast: maybe the mean_predictions or so\n",
    "        mean_pred = out.mean_predictions  # shape (batch, horizon_length)\n",
    "        # Convert to CPU, numpy\n",
    "        mean_np = mean_pred.cpu().numpy()[0]\n",
    "        \n",
    "    # Now derive classification: if any forecasted value beyond threshold ‚Üí failure\n",
    "    if (mean_np > threshold).any():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_timesfm = []\n",
    "y_true_timesfm = []\n",
    "\n",
    "# Assume you have some way of getting \"history_series\" for each test sample and freq\n",
    "# e.g., maybe you pick some numeric feature(s) that indicate machine health over time\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    # Example: pick \"Tool wear\" or combination of features forming a time-series; \n",
    "    # **you will need to decide what constitutes the ‚Äúseries‚Äù** for your problem\n",
    "    # For simplicity assume one feature that evolves over time is available\n",
    "    \n",
    "    history = ...  # your code to get past values for this instance\n",
    "    freq = 0  # or some frequency encoding\n",
    "    thresh = SOME_THRESHOLD  # you define, via domain knowledge or tuning\n",
    "    \n",
    "    pred = predict_with_timesfm(history, freq, thresh)\n",
    "    y_pred_timesfm.append(pred)\n",
    "    y_true_timesfm.append(y_test.iloc[i])\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"\\nüìä TimesFM-based model performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true_timesfm, y_pred_timesfm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true_timesfm, y_pred_timesfm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e16d6c6-8120-42fc-8a28-f5ae7b9514cb",
   "metadata": {},
   "source": [
    "Fine Tune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6bacfa-8661-40fe-96e1-fe98c6d4dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 5. Fine-tuning Chronos\n",
    "# -------------------------------\n",
    "# Convert dataset into text ‚Üí text format\n",
    "train_texts = [\n",
    "    create_prompt(X_train.iloc[i], y_train.iloc[i]) for i in range(len(X_train))\n",
    "]\n",
    "test_texts = [\n",
    "    create_prompt(X_test.iloc[i], y_test.iloc[i]) for i in range(len(X_test))\n",
    "]\n",
    "\n",
    "# Dataset wrapper\n",
    "class PromptDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=256)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "train_dataset = PromptDataset(train_texts, tokenizer)\n",
    "test_dataset = PromptDataset(test_texts, tokenizer)\n",
    "\n",
    "# Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./chronos-finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Fine-tuning Chronos...\")\n",
    "trainer.train()\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Evaluation after fine-tuning\n",
    "# -------------------------------\n",
    "def evaluate_model(trainer, texts, labels):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    outputs = model.generate(**inputs, max_length=50)\n",
    "    preds = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n",
    "\n",
    "    y_pred = [1 if \"1\" in p else 0 for p in preds]\n",
    "    acc = np.mean(np.array(labels) == np.array(y_pred))\n",
    "    return acc\n",
    "\n",
    "acc_finetuned = evaluate_model(trainer, test_texts[:50], y_test.iloc[:50].tolist())\n",
    "print(\"\\nüìä Fine-tuned Accuracy:\", acc_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d78d0b-e0a7-4832-8dc1-b83ef983e1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aacea0-5667-4dc8-951f-08db230f0631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2e996-6353-4a8a-b496-fecb8d77c3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcebf548-f195-4167-b2b6-c6c8935ded67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449ca5e-7478-423f-b158-b44712816d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e1aec-9e7a-49c5-979b-088263e658c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2bf652-2c67-4864-9ae3-07a2889d219b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79473ebb-13c4-4545-86cd-34ba1a4d923e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9d031-ec6b-4fb9-bf77-fe81711b6b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bfe01-9d39-45dd-ac0c-bb45bfaf9a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3cc712-214b-49b0-8d3a-05436fcff596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac7ba9-2714-46e5-b6e2-3c87730ddcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17626aa-80ae-4948-8a3d-ad586dfffecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ddbe1e-3ded-4837-a54a-9fe3e0b446d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec416f-14b3-47f3-b7a2-c29037a01345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69452dd1-8b0e-43c1-83b9-40600457a0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d0d11-a6ed-4c92-bfe3-56799b8be90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a884ad-e2f7-4797-84dd-8f2ec0f0705b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689d9e01-e133-46a7-a59d-defc03fbdf55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206e2cf-8d0c-45f1-a503-32c164ed200c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971cc98-1bbc-41ed-9d8b-35756cb5c7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac35171-5dc6-48fe-ba61-92ea51823889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d0d19-5518-4f0b-af34-9bd5fdbce09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2c248-16ec-4ddf-987a-fd4ad7042ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6b8a3-c372-4f1e-8503-d716387f3740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4746c6a-e040-4e77-8b98-0ebee55339aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
